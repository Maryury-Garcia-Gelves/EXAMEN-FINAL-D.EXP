---
title:  "ANÁLISIS FACTORIAL"
author: "Maryury Johana Garcia Gelves 1950186"
output: github_document
---
# **EXAMEN FINAL DE DISEÑO DE EXPERIMENTOS**

La siguiente base de datos fue una encuesta realizada a **30 jovenes de la Universidad Francisco de Paula Santarder** en la cual se les pregunta la edad y a que se dedican durante las 24 horas del día.

#**Importar base de datos en formato Excel**
```{r}
library(readxl)
datos<- read_excel("C:/Users/USUARIO/Documents/B.D.xlsx")
```
#**Tipificación o estandarización de variables**

La tipificación permite que todas las variables métricas gocen de una misma unidad de medida estadistica.
```{r}
datosm<- datos # nueva base de datos o data frame
datosm<-scale(datosm,center = T, scale = T)
datosm<- as.data.frame(datosm)
```
#**Normalidad Multivariante**

H0: Normalida Multivariante

H1: No Normalidad Multivariante

confianza= 95%

Alfa= 5% = 0,05%

P value > alfa: no se rechaza la H0 (Normalidad)

P value < alfa: se rechaza la H0 (No normalidad)

```{r}
library(MVN)
mvn(datosm[2:7])
```
En el test  Mardia Skewness P value < alfa,se rechaza la H0,es decir no existe normalidad multivariante, en cambio en el test Mardia Kurtosis P value > alfa, no se rechaza H0, es decir existe normalidad multivariable. por tanto, MVN nos da un resultado de NO.

#**Matriz de correlaciones**

H0: Correlación = 0 (no hay correlación)

H1: Correlación diferente de 0 (si hay correlación)

Cuando no se rechaza H0, no se aplica AFE.

se rechaza H0, sí se aplica AFE.

```{r}
library(psych)
corr.test(datosm[,2:7])
correlaciones<- corr.test(datosm[,2:7]) #se crea la matriz de correlaciones 
correlaciones$r # matriz de correlaciones
j <- as.matrix(correlaciones$r)
```

#**Indicadores de aplicabilidad**  

##**Contraste de esfericidad de Bartlett**

H0: Las correlaciones teóricas entre cada par de variables es nulo.

H1: Las correlaciones teóricas entre cada par de variables no es nulo.

P value > alfa: no se aplica el AFE (no se rechaza H0)

P value < alfa: sí se aplica AFE (se rechaza H0)

```{r}
dim(datosm) # tamaño de la muestra= 30 personas
cortest.bartlett(j,n=30)
```
P value < alfa, se rechaza H0, por tanto las correlaciones teóricas entre cada par de variables es nulo,es decir, el análisis factorial exploratorio (AFE) es aplicable.

#**Medida de adecuación muestral de Kaiser, Meyer y Oklin (KMO)**

Estudia variable por variable, si son o no aceptadas en el modelo para hacer AFE.(Qué variables elimino o mantengo)

Se mantiene una variable,si el KMO es igual o mayor a 0,7.

Se elimina una variable, si el KMO < a 0,7.

```{r}
KMO(j)
```

KMO= 0,54, el modelo es Miserable 

Edad=0,40 (inaceptable)

hrs_familia=0,54 (miserable)

hrs_deporte=0,36 (inaceptable)

hrs_redes=0,55 (miserable)

hrs_trabajo= 0,68 (mediocre)

hrs_estudio=0,60 (mediocre)

Todas las variables estan sujetas a ser eliminadas porque los KMO< 0,7

KMO global = 0,54 no se puede hacer AFE.

#**Determinación del número de factores a extraer**

##**Método de las componentes principales iteradas (Ejes principales )**

Este método de las Ejes principales se ocupa cuando no hay normalidad multivariante; pero, tambien es válido para modelos normalidad multivariante.

```{r}
fa.parallel(j, fm= "pa", n.obs = 30, ylabel = "Eigenvalues")
```
Con el método de los ejes principales se extraería solo 1 factor.

##**Método de las componentes principales**

Sirve solo para modelos con normalidad multivariable.

```{r}
fa.parallel(j, fm= "pc", n.obs = 30, ylabel = "Eigenvalues")
```
Con el método de las componentes principales se recomienda extraer 1 factor.

##**Método de la máxima verosimilitud**

Sirve solo para modelos con normalidad multivariante.

```{r}
fa.parallel(j, fm= "ml", n.obs = 30, ylabel = "Eigenvalues")
```
Con el método de la máxima verosimilitud se recomienda extraer 1 factor.

##**Método paralelo con iteraciones**

Sirve solo para modelos con normalida multivariante.

```{r}
library(paran)
paran(j, iterations= 1000, graph = T)
```

Con el método de Horn's (método paralelo con iteraciones)se recomienda extraer 1 factor.

Resumen:

Ejes principales= 1 factor 

Componentes principales= 1 factor 

Máxima verosimilitud= 1 factor

Método paralelo con iteraciones (Horn's)= 1 factor 

En conclusió se extraera 1 factor.

#**Método de extracción de factores**

##**Método de análisis de los componentes principales (ACP)**

```{r}
library(psych)
acp<-principal(j, nfactores=1, rotate= "none")
acp
```
PC1: cargas factoriales de cada variable.

h2: comunalidad (varianza común explicada).Mientras más alta sea h2 es mejor el modelo.Límite entre 0 y 1, es mejor mientras mas cercano este a 1.

u2: Especificidad (varianza residual o varianza no explicada). Mientras más pequeño sea u2 es mejor el modelo. Límite entre 0 y 1.

h2 + u2= 1

Comunalidad + Especificidad =1

Varianza explicada + varianza no explicada = 1

SS loadings=  2.05 (Es la varianza explicada en valores absolutos,o la sumas de los h2).

Proportion Var= 0.34 = 34% (El % que la varianza explicada representa del total).

Lo ideal es que proportion var sea lo más cercano a 1.

RMSR= 0.17 (Raíz cuadrada media de los residuos ).

##**Método de los ejes principales o componentes principales iteradas (CPI)**

```{r}
cpi<-fa(j, nfactores=1, fm="pa", rotate = "none", n.obs = 30)
cpi
```
Proportion Var 0.23= 23%

(RMSR)= 0.13

##**Método de máxima verosimilitud (MVE)**

```{r}
mve<-fa(j, nfactores=1, fm="ml",rotate="none", n.obs = 30)
mve
```
Proportion Var = 0.24 = 24%

(RMSR) = 0.14

###*Resumen*

ACP: Var= 34%          RMSR= 0.17

CPI: var= 23%          RMSR= 0.13

MVE: var= 24%          RMSR= 0.14

Nos quedamos con aquel modelo que tenga la proportion  var más alta y RMSR más pequeño.

#**Representación gráfica de los factores extraídos**

##*Método de análisis de las componentes principales (ACP)*

Solo se gráfica cuando hay 2 factores a extraer,con 1 factor no hay gráfica.

```{r}
plot(acp,labels =row.names(j),cex=.7, ylim=c(-.8,.8) )
```

##*Método de las componentes principales iteradas (CPI)*

```{r}
plot(cpi,labels =row.names(j),cex=.7, ylim=c(-.8,.8) )
```

##*Método de la máxima verosimilitud (MVE)*

```{r}
plot(mve,labels =row.names(j),cex=.1, ylim=c(-.8,.8) )
```


